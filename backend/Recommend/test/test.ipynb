{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Œ TF-IDF (ë¹„ìŠ·í•œ ë§ˆì´ë£¸ ì¶”ì²œ)\n",
    "\n",
    "## âœï¸ DB ì—°ê²°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "load_dotenv(find_dotenv())\n",
    "HOST = os.environ[\"MYSQL_HOST\"] # MySQL host\n",
    "DB = os.environ[\"MYSQL_NAME\"]   # MySQL name\n",
    "USER = os.environ[\"MYSQL_USER\"] # MySQL user\n",
    "PASSWORD = os.environ[\"MYSQL_PASS\"] # MySQL password\n",
    "PORT = int(os.environ[\"MYSQL_PORT\"]) # MySQL port\n",
    "\n",
    "\n",
    "# DB ì—°ê²°\n",
    "db = pymysql.connect(host=HOST, port=PORT, user=USER, passwd=PASSWORD, db=DB, charset='utf8', autocommit=True, cursorclass=pymysql.cursors.DictCursor)\n",
    "#  cursorìƒì„±\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œê¸€, ìˆ«ì, ì˜ë¬¸ë§Œ ê°€ì ¸ì˜´\n",
    "def sub_special(s):\n",
    "    # html íƒœê·¸ ì œê±°\n",
    "    tag_remover = re.compile('<.*?>')\n",
    "    s = re.sub(tag_remover, '', s)\n",
    "    return re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£0-9a-zA-Z ]','',s)\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ\n",
    "def list2str(list):\n",
    "    return \"\".join(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœï¸ ë¡œê·¸ì¸ í•œ ìœ ì €ì˜ í¬íŠ¸í´ë¦¬ì˜¤ Summary ë° Tag ì¡°íšŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´ë§í¬ìŠ¤ìŠ¤ë¡œ ëª¨ë“  ê²ƒì„ í•˜ê³  ì‹¶ì–´í•˜ëŠ” ëª¨ë“  ì•„ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ ì„œë¹„ìŠ¤ëŠ” ë§Œë“¤ì–´ì¡Œì–´ìš”ì•„ì´ í˜¼ìì„œ ìì‹ ì˜ í•˜ë£¨ë¥¼ ëŒì•„ë³´ê³  ê·¸ ë‚ ì˜ ê¸°ë¶„ì„ ê¸°ë¡í•´ë³´ì•„ìš”ë§¤ì¼ ê¸°ë¡í•œ ì¼ìƒì´ ì„ ìƒë‹˜ê³¼ ë¶€ëª¨ë‹˜ì—ê²Œ ì „ë‹¬ë˜ì–´ ëª¨ë‘ì˜ ê¸°ì–µì´ ë  ìˆ˜ ìˆê²Œ í•´ì¤„ê²Œìš”í¬íŠ¸í´ë¦¬ì˜¤ ë‚´ìš©nodejsexpressì•„ì´ë§í¬ë°±ì—”ë“œdockeríƒœê·¸1íƒœê·¸2\n"
     ]
    }
   ],
   "source": [
    "# ë¡œê·¸ì¸ í•œ ìœ ì €ì˜ ë²ˆí˜¸\n",
    "userSeq = 40\n",
    "\n",
    "# í¬íŠ¸í´ë¦¬ì˜¤ summary ì¡°íšŒ\n",
    "port_sql = \"SELECT DISTINCT(`p`.`summary`) AS `portfolios` \\\n",
    "  FROM `portfolio` AS `p` \\\n",
    "  INNER JOIN `arrange` AS `a` ON `p`.`port_seq` = `a`.`port_seq` \\\n",
    "  INNER JOIN `room` AS `r` ON `a`.`room_seq` = `r`.`room_seq` \\\n",
    "  INNER JOIN `user` AS `u` ON `r`.`user_seq` = `u`.`user_seq` \\\n",
    "  WHERE `u`.`user_seq` = \" + str(userSeq) + \";\"\n",
    "\n",
    "cursor.execute(port_sql)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "df_ports = pd.DataFrame(result)\n",
    "ports = sub_special(list2str(list(df_ports[\"portfolios\"])))\n",
    "\n",
    "# Tag ì¡°íšŒ\n",
    "tag_sql = \"SELECT DISTINCT(`t`.`name`) AS `tags` FROM `tag` AS `t` \\\n",
    "  INNER JOIN `arrange` AS `a` ON `t`.`port_seq` = `a`.`port_seq` \\\n",
    "  INNER JOIN `room` AS `r` ON `a`.`room_seq` = `r`.`room_seq` \\\n",
    "  INNER JOIN `user` AS `u` ON `r`.`user_seq` = `u`.`user_seq` \\\n",
    "  WHERE `u`.`user_seq` = \" + str(userSeq) + \";\"\n",
    "\n",
    "cursor.execute(tag_sql)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "df_tags = pd.DataFrame(result)\n",
    "tags = sub_special(list2str(list(df_tags[\"tags\"])))\n",
    "\n",
    "feat_str = ports + tags\n",
    "print(feat_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜•íƒœì†Œ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "file_path = \"./stop_words.txt\"\n",
    "with open(file_path, encoding=\"utf8\") as f:\n",
    "    lines = f.readlines()\n",
    "stop_words = [line.rstrip(\"\\n\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜•íƒœì†Œ ë¶„ì„\n",
    "def morph_and_stopword(text):\n",
    "    \n",
    "    #í˜•íƒœì†Œ ë¶„ì„\n",
    "    words = okt.morphs(text, stem=True)\n",
    "    \n",
    "    # í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ë‹´ì„ í…ìŠ¤íŠ¸\n",
    "    feat_list = []\n",
    "    \n",
    "    #ë¶ˆìš©ì–´ ì²˜ë¦¬\n",
    "    for word in words:\n",
    "        if word not in stop_words and len(word) > 1:\n",
    "            feat_list.append(word)\n",
    "\n",
    "    return list2str(set(feat_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = morph_and_stopword(feat_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“Œ ëª¨ë“  ë°©ì˜ í¬íŠ¸í´ë¦¬ì˜¤ Summary, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ì´ë§í¬ìŠ¤ìŠ¤ë¡œ ëª¨ë“  ê²ƒì„ í•˜ê³  ì‹¶ì–´í•˜ëŠ” ëª¨ë“  ì•„ì´ë¥¼ ìœ„í•´ ìš°ë¦¬ ì„œë¹„ìŠ¤ëŠ” ë§Œë“¤ì–´ì¡Œì–´ìš”ì•„ì´ í˜¼ìì„œ ìì‹ ì˜ í•˜ë£¨ë¥¼ ëŒì•„ë³´ê³  ê·¸ ë‚ ì˜ ê¸°ë¶„ì„ ê¸°ë¡í•´ë³´ì•„ìš”ë§¤ì¼ ê¸°ë¡í•œ ì¼ìƒì´ ì„ ìƒë‹˜ê³¼ ë¶€ëª¨ë‹˜ì—ê²Œ ì „ë‹¬ë˜ì–´ ëª¨ë‘ì˜ ê¸°ì–µì´ ë  ìˆ˜ ìˆê²Œ í•´ì¤„ê²Œìš”í¬íŠ¸í´ë¦¬ì˜¤ ë‚´ìš©fsdfdsfdsfsfSFAFSFSGzzzzzzzzzzzzzzzzzzzzzzzznodejsexpressì•„ì´ë§í¬ë°±ì—”ë“œdockeríƒœê·¸1íƒœê·¸2\n"
     ]
    }
   ],
   "source": [
    "# í¬íŠ¸í´ë¦¬ì˜¤ summary ì¡°íšŒ\n",
    "port_sql = \"SELECT DISTINCT(`p`.`summary`) AS `portfolios`, `r`.`room_seq` \\\n",
    "  FROM `portfolio` AS `p` \\\n",
    "  INNER JOIN `arrange` AS `a` ON `p`.`port_seq` = `a`.`port_seq` \\\n",
    "  INNER JOIN `room` AS `r` ON `a`.`room_seq` = `r`.`room_seq` \\\n",
    "  INNER JOIN `user` AS `u` ON `r`.`user_seq` = `u`.`user_seq`\"\n",
    "\n",
    "cursor.execute(port_sql)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "df_ports = pd.DataFrame(result)\n",
    "ports = sub_special(list2str(list(df_ports[\"portfolios\"])))\n",
    "\n",
    "# Tag ì¡°íšŒ\n",
    "tag_sql = \"SELECT DISTINCT(`t`.`name`) AS `tags` FROM `tag` AS `t` \\\n",
    "  INNER JOIN `arrange` AS `a` ON `t`.`port_seq` = `a`.`port_seq` \\\n",
    "  INNER JOIN `room` AS `r` ON `a`.`room_seq` = `r`.`room_seq` \\\n",
    "  INNER JOIN `user` AS `u` ON `r`.`user_seq` = `u`.`user_seq` \"\n",
    "\n",
    "cursor.execute(tag_sql)\n",
    "result = cursor.fetchall()\n",
    "\n",
    "df_tags = pd.DataFrame(result)\n",
    "tags = sub_special(list2str(list(df_tags[\"tags\"])))\n",
    "\n",
    "feat_str = ports + tags\n",
    "print(feat_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m tf_idf \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m----> 2\u001b[0m tf_idf_matrix \u001b[39m=\u001b[39m tf_idf\u001b[39m.\u001b[39mfit_transform(feat_list)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTF-IDF í–‰ë ¬ì˜ í¬ê¸°(shape): \u001b[39m\u001b[39m\"\u001b[39m, tf_idf_matrix\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m cosine_sim \u001b[39m=\u001b[39m cosine_similarity(tf_idf_matrix, tf_idf_matrix)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_list' is not defined"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf_matrix = tf_idf.fit_transform(feat_list)\n",
    "print(\"TF-IDF í–‰ë ¬ì˜ í¬ê¸°(shape): \", tf_idf_matrix.shape)\n",
    "\n",
    "cosine_sim = cosine_similarity(tf_idf_matrix, tf_idf_matrix)\n",
    "print(\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì—°ì‚° ê²°ê³¼: \",cosine_sim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ë¡œê·¸ì¸ í•œ ë†ˆ]  \n",
    "- ëª¨ë“  í¬íŠ¸í´ë¦¬ì˜¤ ëª©ë¡ summary\n",
    "- ëª¨ë“  íƒœê·¸\n",
    "\n",
    "[ë‹¤ë¥¸ ì‚¬ìš©ì]  \n",
    "- ë°©ì— ë°°ì¹˜ëœ í¬íŠ¸í´ë¦¬ì˜¤ì˜ summary\n",
    "- í•´ë‹¹ í¬íŠ¸í´ë¦¬ì˜¤ë“¤ì˜ íƒœê·¸  \n",
    "\n",
    "ìœ ì €-ìœ ì €ê°€ ì•„ë‹Œ ë°©-ë¡œê·¸ì¸ í•œ ìœ ì €  \n",
    "\n",
    "DataFrame  \n",
    "[ë°© ë²ˆí˜¸][í¬íŠ¸í´ë¦¬ì˜¤ë‚´ìš©][íƒœê·¸ëª©ë¡] ì„\n",
    "[ë°© ë²ˆí˜¸][í˜•íƒœì†Œë¶„ì„ í›„ì˜ feat str]ë¡œ ë§Œë“¤ì–´  \n",
    "pickleë¡œ ì €ì¥ -> ë°ì´í„° ë¡œë”© ì‹œê°„ ê°ì†Œ  \n",
    "\n",
    "\n",
    "\n",
    "ì¸ë±ìŠ¤ë¥¼ ë°© ë²ˆí˜¸ë¡œ ì§€ì •í•˜ê³   \n",
    "ë¡œê·¸ì¸í•œ ìœ ì €ì˜ í…ìŠ¤íŠ¸ë‘  \n",
    "ë°©ì˜ feat strì˜ ìœ ì‚¬ë„ ê³„ì‚°  \n",
    "ìœ ì‚¬ë„ ìˆœ ì •ë ¬í•œ ë’¤ 8ê°œ?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4331abc9abdd1d584db7f832dab711ae7d45f0aa8f7aafc18d69752b2c41e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
